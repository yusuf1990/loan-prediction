{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, gc, warnings, random\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb  \n",
    "from catboost import CatBoostClassifier ,Pool\n",
    "\n",
    "from sklearn.metrics import auc, classification_report, roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG :\n",
    "  SEED = 42\n",
    "  n_splits = 5\n",
    "  catboost_params = {'learning_rate':0.05,'iterations':10000,'eval_metric':'AUC',\n",
    "                      'use_best_model' :True,'verbose':100,'random_seed': 0,\n",
    "                      'devices':'0:1','task_type':\"GPU\",}\n",
    "\n",
    "  lgb_params = {'boosting_type': 'gbdt','objective': 'binary','metric': 'auc','n_estimators': 1500}\n",
    "                #'n_estimators': 500,'sub_sample' : 0.7,'colsample_bytree' : 0.6,\n",
    "                #'seed': SEED,'silent':False,'early_stopping_rounds': 100,\n",
    "               \n",
    "  #remove_features = ['ID', 'country', 'region','target']\n",
    "  categ_features =['count_approveddate_y','count_bank_account_type','count_birthdate','count_creationdate_y','count_employment_status_clients','count_bank_name_clients','count_firstrepaid','count_firstdue','count_creation_y','count_closeddate']\n",
    "   \n",
    "  TARGET_COL = 'good_bad_flag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_data() :\n",
    "    \n",
    "    train_dem=pd.read_csv('traindemographics.csv')\n",
    "    train_perf=pd.read_csv('trainperf.csv')\n",
    "    train_pre=pd.read_csv('trainprevloans.csv')\n",
    "\n",
    "    test_dem=pd.read_csv('testdemographics.csv')\n",
    "    test_perf=pd.read_csv('testperf.csv')\n",
    "    test_pre=pd.read_csv('testprevloans.csv')\n",
    "    train=train_pre.merge(train_perf,on='customerid')\n",
    "    trai=train.merge(train_dem,on='customerid')\n",
    "\n",
    "    test=test_pre.merge(test_perf,on='customerid')\n",
    "    test=test.merge(test_dem,on='customerid')\n",
    "    data = pd.concat([trai, test]).reset_index(drop=True)\n",
    "    train=data.copy()\n",
    "        \n",
    "    import datetime\n",
    "    train['approveddate_y'] = pd.to_datetime(train['approveddate_y'],errors='coerce')\n",
    "    #test['approveddate_y'] = pd.to_datetime(test['approveddate_y'],errors='coerce')\n",
    "    train['monthappy']=train['approveddate_y'].apply(lambda x:x.month)\n",
    "    train['yearappy']=train['approveddate_y'].apply(lambda x:x.day)\n",
    "    train['yeary']=train['approveddate_y'].apply(lambda x:x.year)\n",
    "    train['yy']=train['approveddate_y'].apply(lambda x:x.weekday)\n",
    "    train['yy1']=train['approveddate_y'].apply(lambda x:x.weekofyear)\n",
    "    train['uu']=train['approveddate_y'].apply(lambda x:x.week)\n",
    "    t='''test['yy']=test['approveddate_y'].apply(lambda x:x.weekday)\n",
    "    test['yy1']=test['approveddate_y'].apply(lambda x:x.weekofyear)\n",
    "    test['uu']=test['approveddate_y'].apply(lambda x:x.week)\n",
    "    '''\n",
    "    \n",
    "    train['approveddate_x'] = pd.to_datetime(train['approveddate_x'])\n",
    "    #test['approveddate_x'] = pd.to_datetime(test['approveddate_x'])\n",
    "    #train['monthappy1']=train['approveddate_x'].apply(lambda x:x.month)\n",
    "    #train['yearappy1']=train['approveddate_x'].apply(lambda x:x.day)\n",
    "    #train['yeary1']=train['approveddate_x'].apply(lambda x:x.year)\n",
    "    #train['yy1']=train['approveddate_x'].apply(lambda x:x.weekday)\n",
    "    #test['yy1']=test['approveddate_x'].apply(lambda x:x.weekday)\n",
    "    #train['yy11']=train['approveddate_x'].apply(lambda x:x.weekofyear)\n",
    "    #train['uu2']=train['approveddate_x'].apply(lambda x:x.week)\n",
    "\n",
    "    train['creation_x'] = pd.to_datetime(train['creationdate_x'])\n",
    "    #test['creation_x'] = pd.to_datetime(test['creationdate_x'])\n",
    "    \n",
    "    #train['month']=train['creation_x'].apply(lambda x:x.month)\n",
    "    #train['year']=train['creation_x'].apply(lambda x:x.day)\n",
    "    #train['yea']=train['creation_x'].apply(lambda x:x.year)\n",
    "    #train['wday']=train['creation_x'].apply(lambda x:x.weekday)\n",
    "    #train['wyear']=train['creation_x'].apply(lambda x:x.weekofyear)\n",
    "    #train['wweek']=train['creation_x'].apply(lambda x:x.week)\n",
    "\n",
    "\n",
    "\n",
    "    train['creation_y'] = pd.to_datetime(train['creationdate_y'],errors='coerce')\n",
    "    #train['month0']=train['creation_y'].apply(lambda x:x.month)\n",
    "    train['year0']=train['creation_y'].apply(lambda x:x.day)\n",
    "    #train['yea0']=train['creation_y'].apply(lambda x:x.year)\n",
    "    train['wday0']=train['creation_y'].apply(lambda x:x.weekday)\n",
    "    train['wyear0']=train['creation_y'].apply(lambda x:x.weekofyear)\n",
    "    train['wweek0']=train['creation_y'].apply(lambda x:x.week)\n",
    "\n",
    "    train['firstdue'] = pd.to_datetime(train['firstduedate'])\n",
    "    train['month01']=train['firstdue'].apply(lambda x:x.month)\n",
    "    train['year01']=train['firstdue'].apply(lambda x:x.day)\n",
    "    train['yea01']=train['firstdue'].apply(lambda x:x.year)\n",
    "    train['wday01']=train['firstdue'].apply(lambda x:x.weekday)\n",
    "    train['wyear01']=train['firstdue'].apply(lambda x:x.weekofyear)\n",
    "    train['wweek01']=train['firstdue'].apply(lambda x:x.week)\n",
    "    t='''test['firstdue'] = pd.to_datetime(test['firstduedate'])\n",
    "    test['month01']=test['firstdue'].apply(lambda x:x.month)\n",
    "    test['year01']=test['firstdue'].apply(lambda x:x.day)\n",
    "    test['yea01']=test['firstdue'].apply(lambda x:x.year)\n",
    "    test['wday01']=test['firstdue'].apply(lambda x:x.weekday)\n",
    "    test['wyear01']=test['firstdue'].apply(lambda x:x.weekofyear)\n",
    "    test['wweek01']=test['firstdue'].apply(lambda x:x.week)'''\n",
    "    \n",
    "    \n",
    "\n",
    "    train['firstrepaid'] = pd.to_datetime(train['firstrepaiddate'])\n",
    "    train['month011']=train['firstrepaid'].apply(lambda x:x.month)\n",
    "    train['year011']=train['firstrepaid'].apply(lambda x:x.day)\n",
    "    train['yea011']=train['firstrepaid'].apply(lambda x:x.year)\n",
    "    train['wday011']=train['firstrepaid'].apply(lambda x:x.weekday)\n",
    "    train['wyear011']=train['firstrepaid'].apply(lambda x:x.weekofyear)\n",
    "    train['wweek011']=train['firstrepaid'].apply(lambda x:x.week)\n",
    "    t='''test['firstrepaid'] = pd.to_datetime(test['firstrepaiddate'])\n",
    "    test['month011']=test['firstrepaid'].apply(lambda x:x.month)\n",
    "    test['year011']=test['firstrepaid'].apply(lambda x:x.day)\n",
    "    test['yea011']=test['firstrepaid'].apply(lambda x:x.year)\n",
    "    test['wday011']=test['firstrepaid'].apply(lambda x:x.weekday)\n",
    "    test['wyear011']=test['firstrepaid'].apply(lambda x:x.weekofyear)\n",
    "    test['wweek011']=test['firstrepaid'].apply(lambda x:x.week)'''\n",
    "\n",
    "\n",
    "    train['closeddate'] = pd.to_datetime(train['closeddate'])\n",
    "    train['monthclose']=train['closeddate'].apply(lambda x:x.month)\n",
    "    train['yearclose']=train['closeddate'].apply(lambda x:x.day)\n",
    "    train['yeaclose']=train['closeddate'].apply(lambda x:x.year)\n",
    "    train['wdayclose']=train['closeddate'].apply(lambda x:x.weekday)\n",
    "    train['wyearclose']=train['closeddate'].apply(lambda x:x.weekofyear)\n",
    "    train['wweekclose']=train['closeddate'].apply(lambda x:x.week)\n",
    "   \n",
    "    train['birthdate'] = pd.to_datetime(train['birthdate'])\n",
    "    train['monthclose1']=train['birthdate'].apply(lambda x:x.month)\n",
    "    train['yearclose1']=train['birthdate'].apply(lambda x:x.day)\n",
    "    train['yeaclose1']=train['birthdate'].apply(lambda x:x.year)\n",
    "    train['employment_status_clients']=train['employment_status_clients'].fillna('grow')\n",
    "    \n",
    "    data=train.copy()\n",
    "    data['elapse']=data['totaldue_y']-data['loanamount_y']\n",
    "    \n",
    "    \n",
    "    \n",
    "    col = ['approveddate_y','bank_account_type','closeddate','approveddate_y','creationdate_y','bank_account_type','birthdate','birthdate','creationdate_y','employment_status_clients','bank_name_clients','firstrepaid','firstdue','creation_y','closeddate']\n",
    "    \n",
    "    ## Count of unique features\n",
    "    for i in col:\n",
    "        data['count_'+i] = data[i].map(data[i].value_counts())\n",
    "    # get train , test\n",
    "    train = data[data['customerid'].isin(trai['customerid'].values)]\n",
    "    test = data[data['customerid'].isin(test['customerid'].values)]\n",
    "    features = [x for x in train.columns if x not in \n",
    "                ['systemloanid_y','firstrepaid','firstdue','creation_y','creation_x','wday011','approveddate_x','creationdate_x','bank_name_clients','good_bad_flag','wday0','wday01','yy','yy1','wdayclose','customerid','firstduedate','firstrepaiddate','systemloanid_x','loanamount_x','totaldue_x','termdays_x','loannumber_x','bank_branch_clients','bank_branch_clients','referredby_y','referredby_x','level_of_education_clients','closeddate','approveddate_y','creationdate_y','bank_account_type','birthdate','wday','birthdate','creationdate_y','employment_status_clients']]\n",
    "    return train , test , features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_path = 'Train.csv' ; test_path = 'Test.csv'\n",
    "train , test , features = get_processed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train[features]\n",
    "y=train['good_bad_flag'].map({'Good':1,'Bad':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Fold: 1\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 8932, number of negative: 2022\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1489\n",
      "[LightGBM] [Info] Number of data points in the train set: 10954, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.815410 -> initscore=1.485553\n",
      "[LightGBM] [Info] Start training from score 1.485553\n",
      "[100]\ttraining's auc: 0.998909\tvalid_1's auc: 0.97439\n",
      "[200]\ttraining's auc: 0.999995\tvalid_1's auc: 0.981202\n",
      "[300]\ttraining's auc: 1\tvalid_1's auc: 0.983389\n",
      "[400]\ttraining's auc: 1\tvalid_1's auc: 0.983848\n",
      "[500]\ttraining's auc: 1\tvalid_1's auc: 0.985346\n",
      "[600]\ttraining's auc: 1\tvalid_1's auc: 0.985344\n",
      "[700]\ttraining's auc: 1\tvalid_1's auc: 0.985695\n",
      "[800]\ttraining's auc: 1\tvalid_1's auc: 0.986887\n",
      "[900]\ttraining's auc: 1\tvalid_1's auc: 0.987001\n",
      "[1000]\ttraining's auc: 1\tvalid_1's auc: 0.987559\n",
      "[1100]\ttraining's auc: 1\tvalid_1's auc: 0.987611\n",
      "[1200]\ttraining's auc: 1\tvalid_1's auc: 0.98826\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.988384\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.988005\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.988067\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Fold: 2\n",
      "[LightGBM] [Info] Number of positive: 8932, number of negative: 2022\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1488\n",
      "[LightGBM] [Info] Number of data points in the train set: 10954, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.815410 -> initscore=1.485553\n",
      "[LightGBM] [Info] Start training from score 1.485553\n",
      "[100]\ttraining's auc: 0.998566\tvalid_1's auc: 0.975598\n",
      "[200]\ttraining's auc: 0.999994\tvalid_1's auc: 0.983012\n",
      "[300]\ttraining's auc: 1\tvalid_1's auc: 0.985481\n",
      "[400]\ttraining's auc: 1\tvalid_1's auc: 0.986781\n",
      "[500]\ttraining's auc: 1\tvalid_1's auc: 0.988148\n",
      "[600]\ttraining's auc: 1\tvalid_1's auc: 0.988502\n",
      "[700]\ttraining's auc: 1\tvalid_1's auc: 0.989304\n",
      "[800]\ttraining's auc: 1\tvalid_1's auc: 0.989965\n",
      "[900]\ttraining's auc: 1\tvalid_1's auc: 0.990113\n",
      "[1000]\ttraining's auc: 1\tvalid_1's auc: 0.990433\n",
      "[1100]\ttraining's auc: 1\tvalid_1's auc: 0.990845\n",
      "[1200]\ttraining's auc: 1\tvalid_1's auc: 0.99128\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.991133\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.990997\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.990884\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Fold: 3\n",
      "[LightGBM] [Info] Number of positive: 8932, number of negative: 2022\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1489\n",
      "[LightGBM] [Info] Number of data points in the train set: 10954, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.815410 -> initscore=1.485553\n",
      "[LightGBM] [Info] Start training from score 1.485553\n",
      "[100]\ttraining's auc: 0.999036\tvalid_1's auc: 0.971489\n",
      "[200]\ttraining's auc: 0.99999\tvalid_1's auc: 0.982401\n",
      "[300]\ttraining's auc: 1\tvalid_1's auc: 0.985824\n",
      "[400]\ttraining's auc: 1\tvalid_1's auc: 0.987349\n",
      "[500]\ttraining's auc: 1\tvalid_1's auc: 0.989149\n",
      "[600]\ttraining's auc: 1\tvalid_1's auc: 0.989982\n",
      "[700]\ttraining's auc: 1\tvalid_1's auc: 0.991202\n",
      "[800]\ttraining's auc: 1\tvalid_1's auc: 0.991232\n",
      "[900]\ttraining's auc: 1\tvalid_1's auc: 0.991867\n",
      "[1000]\ttraining's auc: 1\tvalid_1's auc: 0.991748\n",
      "[1100]\ttraining's auc: 1\tvalid_1's auc: 0.992375\n",
      "[1200]\ttraining's auc: 1\tvalid_1's auc: 0.992561\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.992838\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.993194\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.993413\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Fold: 4\n",
      "[LightGBM] [Info] Number of positive: 8932, number of negative: 2023\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1489\n",
      "[LightGBM] [Info] Number of data points in the train set: 10955, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.815335 -> initscore=1.485059\n",
      "[LightGBM] [Info] Start training from score 1.485059\n",
      "[100]\ttraining's auc: 0.99907\tvalid_1's auc: 0.968285\n",
      "[200]\ttraining's auc: 0.999997\tvalid_1's auc: 0.97656\n",
      "[300]\ttraining's auc: 1\tvalid_1's auc: 0.978335\n",
      "[400]\ttraining's auc: 1\tvalid_1's auc: 0.980514\n",
      "[500]\ttraining's auc: 1\tvalid_1's auc: 0.982329\n",
      "[600]\ttraining's auc: 1\tvalid_1's auc: 0.983003\n",
      "[700]\ttraining's auc: 1\tvalid_1's auc: 0.983563\n",
      "[800]\ttraining's auc: 1\tvalid_1's auc: 0.983955\n",
      "[900]\ttraining's auc: 1\tvalid_1's auc: 0.983906\n",
      "[1000]\ttraining's auc: 1\tvalid_1's auc: 0.984066\n",
      "[1100]\ttraining's auc: 1\tvalid_1's auc: 0.984402\n",
      "[1200]\ttraining's auc: 1\tvalid_1's auc: 0.985116\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.985279\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.984878\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.984362\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Fold: 5\n",
      "[LightGBM] [Info] Number of positive: 8932, number of negative: 2023\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1489\n",
      "[LightGBM] [Info] Number of data points in the train set: 10955, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.815335 -> initscore=1.485059\n",
      "[LightGBM] [Info] Start training from score 1.485059\n",
      "[100]\ttraining's auc: 0.998849\tvalid_1's auc: 0.979346\n",
      "[200]\ttraining's auc: 0.999993\tvalid_1's auc: 0.984968\n",
      "[300]\ttraining's auc: 1\tvalid_1's auc: 0.98577\n",
      "[400]\ttraining's auc: 1\tvalid_1's auc: 0.986197\n",
      "[500]\ttraining's auc: 1\tvalid_1's auc: 0.985913\n",
      "[600]\ttraining's auc: 1\tvalid_1's auc: 0.987065\n",
      "[700]\ttraining's auc: 1\tvalid_1's auc: 0.986731\n",
      "[800]\ttraining's auc: 1\tvalid_1's auc: 0.987017\n",
      "[900]\ttraining's auc: 1\tvalid_1's auc: 0.987132\n",
      "[1000]\ttraining's auc: 1\tvalid_1's auc: 0.987504\n",
      "[1100]\ttraining's auc: 1\tvalid_1's auc: 0.987573\n",
      "[1200]\ttraining's auc: 1\tvalid_1's auc: 0.988052\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.988145\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.987896\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.987782\n",
      "--------------------------------------------------\n",
      "OOF score : 0.9887748218608104\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=CFG.n_splits,shuffle=True, random_state=524)\n",
    "\n",
    "X , y   = train[features] , train['good_bad_flag'].map({'Good':1,'Bad':0})\n",
    "\n",
    "oof_lgb = np.zeros((train.shape[0],))\n",
    "test[CFG.TARGET_COL]= 0\n",
    "lgb_preds = []\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(skf.split(X,y)):\n",
    "    print(50*'-')\n",
    "    print('Fold:',fold_+1)\n",
    "\n",
    "    tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx] \n",
    "    vl_x, vl_y = X.iloc[val_idx,:], y[val_idx] \n",
    "        \n",
    "    train_data = lgb.Dataset(tr_x, label=tr_y,categorical_feature=CFG.categ_features)\n",
    "    valid_data = lgb.Dataset(vl_x, label=vl_y,categorical_feature=CFG.categ_features)\n",
    "\n",
    "    estimator = lgb.train(CFG.lgb_params,train_data,valid_sets = [train_data,valid_data],verbose_eval = 100)\n",
    "    \n",
    "    y_pred_val = estimator.predict(vl_x,num_iteration=estimator.best_iteration)\n",
    "    oof_lgb[val_idx] = y_pred_val\n",
    "    \n",
    "    y_pred_test = estimator.predict(test[features],num_iteration=estimator.best_iteration)\n",
    "    lgb_preds.append(y_pred_test)\n",
    "    print(50*'-')\n",
    "\n",
    "print('OOF score :',roc_auc_score(y, oof_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=pd.read_csv('SampleSubmission.csv')\n",
    "SUB_FILE_NAME = 'ee.csv' ;sub_df = test[['customerid']].copy() ; sub_df['ggood_Bad_flag'] = (np.mean(lgb_preds,axis=0)>0.5)*1\n",
    "\n",
    "v=sub_df.to_csv(SUB_FILE_NAME, index=False)\n",
    "#sub_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=pd.read_csv('ee.csv')\n",
    "v=v.rename(columns={'customerid':'hope'})\n",
    "t=pd.concat([cv,v],axis=1)\n",
    "\n",
    "t.drop(['hope','Good_Bad_flag'],axis=1,inplace=True)\n",
    "\n",
    "t.dropna(inplace=True)\n",
    "\n",
    "tv=t.rename(columns={'ggood_Bad_flag':'Good_Bad_flag'})\n",
    "\n",
    "tv.to_csv('YusufJimoh.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
